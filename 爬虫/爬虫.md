# 爬虫

[TOC]

<!-- toc -->

---

## 使用requests和loginform模拟登陆网站

```python
import requests
from loginform import fill_login_form
from bs4 import BeautifulSoup as bs

url = 'xxx'
user = 'xxx'
passwd = 'xxx'

session = requests.Session()
headers = {} # 有些网站可能需要预设一些header才能访问

r = session.get(url, headers=headers)
(form, login_url, method) = fill_login_form(url, r.text, user, passwd)

r = session.request(method, login_url, data=dict(form))

print(r.status_code)  # 返回200不能证明登陆成功
r.encoding = 'xxx'    # 可能需要更改编码

# 使用bs4对结果进行解析，看是否登陆成功，主要看页面中是否已经包含了用户名
soup = bs(r.text)
soup.find_all('xxx')

# 接下来就可以使用session去访问该网站的其他页面了
```

fill_login_form 返回包含3个元素的元组，分别是所有表单项组成的列表（每隔表单项是一个(x,y)类型的元组），登陆提交表单的地址，提交表单的方法。