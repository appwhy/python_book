
<!DOCTYPE HTML>
<html lang="zh-hans" >
    <head>
        <meta charset="UTF-8">
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <title>NLP 相关算法 · python_book</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="GitBook 3.2.3">
        <meta name="author" content="appwhy">
        
        
    
    
    <link rel="stylesheet" href="../gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-search-pro/search.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-prism/prism-base16-ateliersulphurpool.light.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-code/plugin.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-mermaid-gb3/mermaid/mermaid.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-splitter/splitter.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-anchor-navigation-ex/style/plugin.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-tbfed-pagefooter/footer.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-fontsettings/website.css">
                
            
        

    

    
        
    
        
    
        
    
        
    
        
    
        
    


    

        
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="../gitbook/images/favicon.ico" type="image/x-icon">

    
    <link rel="next" href="../python/python.html" />
    
    
    <link rel="prev" href="NLP.html" />
    

    </head>
    <body>
        
<div class="book">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="输入并搜索" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    
    
        
        <li>
            <a href="https://github.com/appwhy" target="_blank" class="custom-link">Home</a>
        </li>
    
    

    
    <li class="divider"></li>
    

    
        
        
    
        <li class="chapter " data-level="1.1" data-path="../">
            
                <a href="../">
            
                    
                    简介
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2" data-path="../django/django.html">
            
                <a href="../django/django.html">
            
                    
                    django
            
                </a>
            

            
        </li>
    

    
        
        <li class="divider"></li>
        
        
    
        <li class="chapter " data-level="2.1" data-path="NLP.html">
            
                <a href="NLP.html">
            
                    
                    nlp
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter active" data-level="2.1.1" data-path="NLP 相关算法.html">
            
                <a href="NLP 相关算法.html">
            
                    
                    NLP 相关算法
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

    
        
        <li class="divider"></li>
        
        
    
        <li class="chapter " data-level="3.1" data-path="../python/python.html">
            
                <a href="../python/python.html">
            
                    
                    python
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="3.1.1" data-path="../python/python其他库.html">
            
                <a href="../python/python其他库.html">
            
                    
                    python其他库
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.1.2" data-path="../python/python常用库.html">
            
                <a href="../python/python常用库.html">
            
                    
                    python常用库
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.1.3" data-path="../python/python环境.html">
            
                <a href="../python/python环境.html">
            
                    
                    python环境
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.1.4" data-path="../python/基础知识.html">
            
                <a href="../python/基础知识.html">
            
                    
                    基础知识
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.1.5" data-path="../python/小技巧.html">
            
                <a href="../python/小技巧.html">
            
                    
                    小技巧
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.1.6" data-path="../python/常用知识点.html">
            
                <a href="../python/常用知识点.html">
            
                    
                    常用知识点
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.1.7" data-path="../python/常见问题.html">
            
                <a href="../python/常见问题.html">
            
                    
                    常见问题
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

    
        
        <li class="divider"></li>
        
        
    
        <li class="chapter " data-level="4.1" >
            
                <span>
            
                    
                    其他
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="4.1.1" data-path="../其他/数据库.html">
            
                <a href="../其他/数据库.html">
            
                    
                    数据库
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

    
        
        <li class="divider"></li>
        
        
    
        <li class="chapter " data-level="5.1" data-path="../爬虫/爬虫.html">
            
                <a href="../爬虫/爬虫.html">
            
                    
                    爬虫
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="5.1.1" data-path="../爬虫/bs4.html">
            
                <a href="../爬虫/bs4.html">
            
                    
                    bs4
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="5.1.2" data-path="../爬虫/requests.html">
            
                <a href="../爬虫/requests.html">
            
                    
                    requests
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="5.1.3" data-path="../爬虫/scrapy.html">
            
                <a href="../爬虫/scrapy.html">
            
                    
                    scrapy
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="5.1.4" data-path="../爬虫/常见问题.html">
            
                <a href="../爬虫/常见问题.html">
            
                    
                    常见问题
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
            本书使用 GitBook 发布
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href=".." >NLP 相关算法</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <div id="anchor-navigation-ex-navbar"><i class="fa fa-navicon"></i><ul><li><span class="title-icon "></span><a href="#nlp-&#x76F8;&#x5173;&#x7B97;&#x6CD5;"><b>1. </b>NLP &#x76F8;&#x5173;&#x7B97;&#x6CD5;</a></li><ul><li><span class="title-icon "></span><a href="#&#x6587;&#x672C;&#x9884;&#x5904;&#x7406;&#x5206;&#x8BCD;"><b>1.1. </b>&#x6587;&#x672C;&#x9884;&#x5904;&#x7406;(&#x5206;&#x8BCD;)</a></li><ul><li><span class="title-icon "></span><a href="#hmm-&#x6A21;&#x578B;"><b>1.1.1. </b>HMM &#x6A21;&#x578B;</a></li><li><span class="title-icon "></span><a href="#crf&#x6A21;&#x578B;"><b>1.1.2. </b>CRF&#x6A21;&#x578B;</a></li></ul><li><span class="title-icon "></span><a href="#&#x7279;&#x5F81;&#x5411;&#x91CF;"><b>1.2. </b>&#x7279;&#x5F81;&#x5411;&#x91CF;</a></li><ul><li><span class="title-icon "></span><a href="#&#x8BCD;&#x888B;&#x6A21;&#x578B;&#xFF08;bow&#xFF09;"><b>1.2.1. </b>&#x8BCD;&#x888B;&#x6A21;&#x578B;&#xFF08;BOW&#xFF09;</a></li><li><span class="title-icon "></span><a href="#tf-idf&#x7B97;&#x6CD5;"><b>1.2.2. </b>tf-idf&#x7B97;&#x6CD5;</a></li></ul><li><span class="title-icon "></span><a href="#&#x5206;&#x8BCD;"><b>1.3. </b>&#x5206;&#x8BCD;</a></li><ul><li><span class="title-icon "></span><a href="#&#x7ED3;&#x5DF4;&#x5206;&#x8BCD;"><b>1.3.1. </b>&#x7ED3;&#x5DF4;&#x5206;&#x8BCD;</a></li><li><span class="title-icon "></span><a href="#hanlp&#x5206;&#x8BCD;"><b>1.3.2. </b>hanlp&#x5206;&#x8BCD;</a></li></ul><li><span class="title-icon "></span><a href="#&#x6587;&#x672C;&#x6458;&#x8981;"><b>1.4. </b>&#x6587;&#x672C;&#x6458;&#x8981;</a></li><li><span class="title-icon "></span><a href="#&#x6A21;&#x578B;"><b>1.5. </b>&#x6A21;&#x578B;</a></li><li><span class="title-icon "></span><a href="#&#x6587;&#x672C;&#x805A;&#x7C7B;"><b>1.6. </b>&#x6587;&#x672C;&#x805A;&#x7C7B;</a></li><li><span class="title-icon "></span><a href="#&#x964D;&#x7EF4;&#x5DE5;&#x5177;"><b>1.7. </b>&#x964D;&#x7EF4;&#x5DE5;&#x5177;</a></li><li><span class="title-icon "></span><a href="#&#x6587;&#x672C;&#x5206;&#x7C7B;"><b>1.8. </b>&#x6587;&#x672C;&#x5206;&#x7C7B;</a></li><li><span class="title-icon "></span><a href="#&#x60C5;&#x611F;&#x5206;&#x6790;"><b>1.9. </b>&#x60C5;&#x611F;&#x5206;&#x6790;</a></li></ul></ul></div><a href="#nlp-&#x76F8;&#x5173;&#x7B97;&#x6CD5;" id="anchorNavigationExGoTop"><i class="fa fa-arrow-up"></i></a><h1 id="nlp-&#x76F8;&#x5173;&#x7B97;&#x6CD5;"><a name="nlp-&#x76F8;&#x5173;&#x7B97;&#x6CD5;" class="anchor-navigation-ex-anchor" href="#nlp-&#x76F8;&#x5173;&#x7B97;&#x6CD5;"><i class="fa fa-link" aria-hidden="true"></i></a>1. NLP &#x76F8;&#x5173;&#x7B97;&#x6CD5;</h1>
<p>[TOC]</p>
<!-- toc -->
<ul>
<li><a href="#%E6%96%87%E6%9C%AC%E9%A2%84%E5%A4%84%E7%90%86%E5%88%86%E8%AF%8D">&#x6587;&#x672C;&#x9884;&#x5904;&#x7406;(&#x5206;&#x8BCD;)</a><ul>
<li><a href="#hmm-%E6%A8%A1%E5%9E%8B">HMM &#x6A21;&#x578B;</a></li>
<li><a href="#crf%E6%A8%A1%E5%9E%8B">CRF&#x6A21;&#x578B;</a></li>
</ul>
</li>
<li><a href="#%E7%89%B9%E5%BE%81%E5%90%91%E9%87%8F">&#x7279;&#x5F81;&#x5411;&#x91CF;</a><ul>
<li><a href="#%E8%AF%8D%E8%A2%8B%E6%A8%A1%E5%9E%8Bbow">&#x8BCD;&#x888B;&#x6A21;&#x578B;&#xFF08;BOW&#xFF09;</a></li>
<li><a href="#tf-idf%E7%AE%97%E6%B3%95">tf-idf&#x7B97;&#x6CD5;</a></li>
</ul>
</li>
<li><a href="#%E5%88%86%E8%AF%8D">&#x5206;&#x8BCD;</a><ul>
<li><a href="#%E7%BB%93%E5%B7%B4%E5%88%86%E8%AF%8D">&#x7ED3;&#x5DF4;&#x5206;&#x8BCD;</a></li>
<li><a href="#hanlp%E5%88%86%E8%AF%8D">hanlp&#x5206;&#x8BCD;</a></li>
</ul>
</li>
<li><a href="#%E6%96%87%E6%9C%AC%E6%91%98%E8%A6%81">&#x6587;&#x672C;&#x6458;&#x8981;</a></li>
<li><a href="#%E6%A8%A1%E5%9E%8B">&#x6A21;&#x578B;</a></li>
<li><a href="#%E6%96%87%E6%9C%AC%E8%81%9A%E7%B1%BB">&#x6587;&#x672C;&#x805A;&#x7C7B;</a></li>
<li><a href="#%E9%99%8D%E7%BB%B4%E5%B7%A5%E5%85%B7">&#x964D;&#x7EF4;&#x5DE5;&#x5177;</a></li>
<li><a href="#%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB">&#x6587;&#x672C;&#x5206;&#x7C7B;</a></li>
<li><a href="#%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90">&#x60C5;&#x611F;&#x5206;&#x6790;</a></li>
</ul>
<!-- tocstop -->
<hr>
<h2 id="&#x6587;&#x672C;&#x9884;&#x5904;&#x7406;&#x5206;&#x8BCD;"><a name="&#x6587;&#x672C;&#x9884;&#x5904;&#x7406;&#x5206;&#x8BCD;" class="anchor-navigation-ex-anchor" href="#&#x6587;&#x672C;&#x9884;&#x5904;&#x7406;&#x5206;&#x8BCD;"><i class="fa fa-link" aria-hidden="true"></i></a>1.1. &#x6587;&#x672C;&#x9884;&#x5904;&#x7406;(&#x5206;&#x8BCD;)</h2>
<p>HMM&#xFF08;&#x9690;&#x9A6C;&#x5C14;&#x53EF;&#x592B;&#x6A21;&#x578B;&#xFF09;&#x548C; CRF&#xFF08;&#x6761;&#x4EF6;&#x968F;&#x673A;&#x573A;&#xFF09;&#x7B97;&#x6CD5;&#x5E38;&#x5E38;&#x88AB;&#x7528;&#x4E8E;&#x5206;&#x8BCD;&#x3001;&#x53E5;&#x6CD5;&#x5206;&#x6790;&#x3001;&#x547D;&#x540D;&#x5B9E;&#x4F53;&#x8BC6;&#x522B;&#x3001;&#x8BCD;&#x6027;&#x6807;&#x6CE8;&#x7B49;&#x3002;</p>
<p>&#x4E24;&#x8005;&#x4E4B;&#x95F4;&#x6709;&#x5F88;&#x5927;&#x7684;&#x5171;&#x540C;&#x70B9;&#xFF0C;&#x6240;&#x4EE5;&#x5728;&#x5F88;&#x591A;&#x5E94;&#x7528;&#x4E0A;&#x5F80;&#x5F80;&#x662F;&#x91CD;&#x53E0;&#x7684;&#xFF0C;&#x4F46;&#x5728;&#x547D;&#x540D;&#x5B9E;&#x4F53;&#x3001;&#x53E5;&#x6CD5;&#x5206;&#x6790;&#x7B49;&#x9886;&#x57DF; CRF &#x4F3C;&#x4E4E;&#x66F4;&#x80DC;&#x4E00;&#x7B79;&#x3002;</p>
<p><strong>&#x751F;&#x6210;&#x5F0F;&#x6A21;&#x578B;&#xFF1A;</strong>P(Y|X)= P(X,Y)/ P(X)&#x3002;&#x4F30;&#x8BA1;&#x7684;&#x662F;&#x8054;&#x5408;&#x6982;&#x7387;&#x5206;&#x5E03;P(Y, X)&#x3002;&#x4E3B;&#x8981;&#x5173;&#x5FC3;&#x7684;&#x662F;&#x7ED9;&#x5B9A;&#x8F93;&#x5165;X&#xFF0C;&#x4EA7;&#x751F;&#x8F93;&#x51FA; Y &#x7684;&#x751F;&#x6210;&#x5173;&#x7CFB;&#x3002;</p>
<p><strong>&#x5224;&#x522B;&#x5F0F;&#x6A21;&#x578B;&#xFF1A;</strong>P(Y, X)=P(Y|X)*P(X)&#x3002;&#x4F30;&#x8BA1;&#x7684;&#x662F;&#x6761;&#x4EF6;&#x6982;&#x7387;&#x5206;&#x5E03; P(Y|X)&#x3002;&#x4E3B;&#x8981;&#x5173;&#x5FC3;&#x7684;&#x662F;&#x5BF9;&#x4E8E;&#x7ED9;&#x5B9A;&#x7684;&#x8F93;&#x5165; X&#xFF0C;&#x5E94;&#x8BE5;&#x9884;&#x6D4B;&#x4EC0;&#x4E48;&#x6837;&#x7684;&#x8F93;&#x51FA; Y&#x3002;</p>
<p>&#x751F;&#x6210;&#x5F0F;&#x6A21;&#x578B;&#x548C;&#x5224;&#x522B;&#x5F0F;&#x6A21;&#x578B;&#x90FD;&#x7528;&#x4E8E;&#x6709;&#x76D1;&#x7763;&#x5B66;&#x4E60;</p>
<p>&#x6A21;&#x578B;&#xFF1A;</p>
<ul>
<li>&#x751F;&#x6210;&#x5F0F;&#x6A21;&#x578B;&#xFF1A;HMM&#x3001;Gaussian&#x3001; Naive Bayes&#x3001;Mixtures of multinomials &#x7B49;&#x3002;</li>
<li>&#x5224;&#x522B;&#x5F0F;&#x6A21;&#x578B;&#xFF1A;CRF&#x3001;K &#x8FD1;&#x90BB;&#x6CD5;&#x3001;&#x611F;&#x77E5;&#x673A;&#x3001;&#x51B3;&#x7B56;&#x6811;&#x3001;&#x903B;&#x8F91;&#x65AF;&#x8C1B;&#x56DE;&#x5F52;&#x6A21;&#x578B;&#x3001;&#x6700;&#x5927;&#x71B5;&#x6A21;&#x578B;&#x3001;&#x652F;&#x6301;&#x5411;&#x91CF;&#x673A;&#x3001;&#x63D0;&#x5347;&#x65B9;&#x6CD5;&#x7B49;&#x3002;</li>
</ul>
<h3 id="hmm-&#x6A21;&#x578B;"><a name="hmm-&#x6A21;&#x578B;" class="anchor-navigation-ex-anchor" href="#hmm-&#x6A21;&#x578B;"><i class="fa fa-link" aria-hidden="true"></i></a>1.1.1. HMM &#x6A21;&#x578B;</h3>
<h3 id="crf&#x6A21;&#x578B;"><a name="crf&#x6A21;&#x578B;" class="anchor-navigation-ex-anchor" href="#crf&#x6A21;&#x578B;"><i class="fa fa-link" aria-hidden="true"></i></a>1.1.2. CRF&#x6A21;&#x578B;</h3>
<h2 id="&#x7279;&#x5F81;&#x5411;&#x91CF;"><a name="&#x7279;&#x5F81;&#x5411;&#x91CF;" class="anchor-navigation-ex-anchor" href="#&#x7279;&#x5F81;&#x5411;&#x91CF;"><i class="fa fa-link" aria-hidden="true"></i></a>1.2. &#x7279;&#x5F81;&#x5411;&#x91CF;</h2>
<h3 id="&#x8BCD;&#x888B;&#x6A21;&#x578B;&#xFF08;bow&#xFF09;"><a name="&#x8BCD;&#x888B;&#x6A21;&#x578B;&#xFF08;bow&#xFF09;" class="anchor-navigation-ex-anchor" href="#&#x8BCD;&#x888B;&#x6A21;&#x578B;&#xFF08;bow&#xFF09;"><i class="fa fa-link" aria-hidden="true"></i></a>1.2.1. &#x8BCD;&#x888B;&#x6A21;&#x578B;&#xFF08;BOW&#xFF09;</h3>
<p>&#x628A;&#x6587;&#x672C;&#xFF08;&#x6BB5;&#x843D;&#x6216;&#x8005;&#x6587;&#x6863;&#xFF09;&#x770B;&#x4F5C;&#x662F;&#x65E0;&#x5E8F;&#x7684;&#x8BCD;&#x6C47;&#x96C6;&#x5408;&#xFF0C;&#x5FFD;&#x7565;&#x8BED;&#x6CD5;&#x751A;&#x81F3;&#x662F;&#x5355;&#x8BCD;&#x7684;&#x987A;&#x5E8F;&#xFF0C;&#x628A;&#x6BCF;&#x4E00;&#x4E2A;&#x5355;&#x8BCD;&#x90FD;&#x8FDB;&#x884C;&#x7EDF;&#x8BA1;&#xFF0C;&#x540C;&#x65F6;&#x8BA1;&#x7B97;&#x6BCF;&#x4E2A;&#x5355;&#x8BCD;&#x51FA;&#x73B0;&#x7684;&#x6B21;&#x6570;&#xFF0C;&#x5E38;&#x5E38;&#x88AB;&#x7528;&#x5728;&#x6587;&#x672C;&#x5206;&#x7C7B;&#x4E2D;&#xFF0C;&#x5982;&#x8D1D;&#x53F6;&#x65AF;&#x7B97;&#x6CD5;&#x3001;LDA &#x548C; LSA &#x7B49;&#x3002;</p>
<pre class="language-"><code class="lang-python"><span class="token keyword">from</span> gensim <span class="token keyword">import</span> corpora

<span class="token comment">#tokenized&#x662F;[[token,],[token,]]</span>
dictionary <span class="token operator">=</span> corpora<span class="token punctuation">.</span>Dictionary<span class="token punctuation">(</span>tokenized<span class="token punctuation">)</span>
<span class="token comment">#&#x4FDD;&#x5B58;&#x8BCD;&#x5178;</span>
dictionary<span class="token punctuation">.</span>save<span class="token punctuation">(</span><span class="token string">&apos;deerwester.dict&apos;</span><span class="token punctuation">)</span> 

dictionary<span class="token punctuation">.</span>token2id  <span class="token comment"># &#x5F97;&#x5230;&#x5355;&#x8BCD;&#x4E0E;id&#x7684;&#x6620;&#x5C04;</span>
dictionary<span class="token punctuation">.</span>doc2bow<span class="token punctuation">(</span>sentence<span class="token punctuation">)</span>  <span class="token comment"># &#x5C06;[token, ]&#x8F6C;&#x5316;&#x4E3A;&#x7A00;&#x758F;&#x77E9;&#x9635;[(index,count), ]</span>
</code></pre>
<pre class="language-"><code class="lang-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>feature_extraction<span class="token punctuation">.</span>text <span class="token keyword">import</span> CountVectorizer

vec <span class="token operator">=</span> CountVectorizer<span class="token punctuation">(</span>
    analyzer<span class="token operator">=</span><span class="token string">&apos;word&apos;</span><span class="token punctuation">,</span> <span class="token comment"># tokenise by character ngrams</span>
    max_features<span class="token operator">=</span><span class="token number">4000</span><span class="token punctuation">,</span>  <span class="token comment"># keep the most common 1000 ngrams</span>
<span class="token punctuation">)</span>
<span class="token comment"># &#x6839;&#x636E;corpus&#x521B;&#x9020;&#x76F8;&#x5E94;&#x7684;&#x8BCD;&#x5178;</span>
vec<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>corpus<span class="token punctuation">)</span>  <span class="token comment"># corpus = [str,str]&#xFF0C;str&#x4F1A;&#x88AB;tokenize</span>

vec<span class="token punctuation">.</span>vocabulary_  <span class="token comment"># &#x5F97;&#x5230;&#x8BCD;&#x8BED;&#x4E0E;id&#x7684;&#x6620;&#x5C04;</span>
vec<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>corpus<span class="token punctuation">)</span>  <span class="token comment"># &#x5C06;curpos&#x8F6C;&#x5316;&#x4E3A;&#x5411;&#x91CF;&#xFF0C;&#x7A00;&#x758F;&#x77E9;&#x9635;</span>
vec<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>corpus<span class="token punctuation">)</span><span class="token punctuation">.</span>todense<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># numpy&#x7684;&#x7A20;&#x5BC6;&#x77E9;&#x9635;</span>
</code></pre>
<h3 id="tf-idf&#x7B97;&#x6CD5;"><a name="tf-idf&#x7B97;&#x6CD5;" class="anchor-navigation-ex-anchor" href="#tf-idf&#x7B97;&#x6CD5;"><i class="fa fa-link" aria-hidden="true"></i></a>1.2.2. tf-idf&#x7B97;&#x6CD5;</h3>
<pre class="language-"><code class="lang-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>feature_extraction<span class="token punctuation">.</span>text <span class="token keyword">import</span> TfidfTransformer<span class="token punctuation">,</span> TfidfVectorizer

<span class="token comment">#&#x5C06;&#x6587;&#x672C;&#x4E2D;&#x7684;&#x8BCD;&#x8BED;&#x8F6C;&#x6362;&#x4E3A;&#x8BCD;&#x9891;&#x77E9;&#x9635; &#x77E9;&#x9635;&#x5143;&#x7D20;a[i][j] &#x8868;&#x793A;j&#x8BCD;&#x5728;i&#x7C7B;&#x6587;&#x672C;&#x4E0B;&#x7684;&#x8BCD;&#x9891;</span>
vectorizer <span class="token operator">=</span> TfidfVectorizer<span class="token punctuation">(</span>sublinear_tf<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> max_df<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span>
<span class="token comment">#&#x7EDF;&#x8BA1;&#x6BCF;&#x4E2A;&#x8BCD;&#x8BED;&#x7684;tf-idf&#x6743;&#x503C;</span>
transformer <span class="token operator">=</span> TfidfTransformer<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment"># ?&#x7B2C;&#x4E00;&#x4E2A;fit_transform&#x662F;&#x8BA1;&#x7B97;tf-idf &#x7B2C;&#x4E8C;&#x4E2A;fit_transform&#x662F;&#x5C06;&#x6587;&#x672C;&#x8F6C;&#x4E3A;&#x8BCD;&#x9891;&#x77E9;&#x9635;</span>
tfidf <span class="token operator">=</span> transformer<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>vectorizer<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>centences<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># centences&#x662F;[str,]</span>

vectorizer<span class="token punctuation">.</span>get_feature_names<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># &#x83B7;&#x53D6;&#x8BCD;&#x888B;&#x6A21;&#x578B;&#x4E2D;&#x7684;&#x6240;&#x6709;&#x8BCD;&#x8BED;&#x7EC4;&#x6210;&#x7684;list</span>
tfidf<span class="token punctuation">.</span>toarray<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre>
<h4 id="textrank&#x7B97;&#x6CD5;"><a name="textrank&#x7B97;&#x6CD5;" class="anchor-navigation-ex-anchor" href="#textrank&#x7B97;&#x6CD5;"><i class="fa fa-link" aria-hidden="true"></i></a>textrank&#x7B97;&#x6CD5;</h4>
<h4 id="&#x8BCD;&#x5411;&#x91CF;word2vec"><a name="&#x8BCD;&#x5411;&#x91CF;word2vec" class="anchor-navigation-ex-anchor" href="#&#x8BCD;&#x5411;&#x91CF;word2vec"><i class="fa fa-link" aria-hidden="true"></i></a>&#x8BCD;&#x5411;&#x91CF;Word2Vec</h4>
<pre class="language-"><code class="lang-python"><span class="token keyword">from</span> gensim<span class="token punctuation">.</span>models <span class="token keyword">import</span> Word2Vec
model <span class="token operator">=</span> Word2Vec<span class="token punctuation">(</span>
    sentences<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>
    corpus_file<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>
    size<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span>
    alpha<span class="token operator">=</span><span class="token number">0.025</span><span class="token punctuation">,</span>
    window<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span>
    min_count<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span>
    max_vocab_size<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>
    sample<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">,</span>
    seed<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>
    workers<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>
    min_alpha<span class="token operator">=</span><span class="token number">0.0001</span><span class="token punctuation">,</span>
    sg<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>
    hs<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>
    negative<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span>
    ns_exponent<span class="token operator">=</span><span class="token number">0.75</span><span class="token punctuation">,</span>
    cbow_mean<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>
    hashfxn<span class="token operator">=</span><span class="token operator">&lt;</span>built<span class="token operator">-</span><span class="token keyword">in</span> function <span class="token builtin">hash</span><span class="token operator">&gt;</span><span class="token punctuation">,</span>
    <span class="token builtin">iter</span><span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span>
    null_word<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>
    trim_rule<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>
    sorted_vocab<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>
    batch_words<span class="token operator">=</span><span class="token number">10000</span><span class="token punctuation">,</span>
    compute_loss<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>
    callbacks<span class="token operator">=</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    max_final_vocab<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>
<span class="token triple-quoted-string string">&quot;&quot;&quot;
sentences: [[token,], [token,]]
sg: sg=1 &#x662F;skip-gram&#x7B97;&#x6CD5;&#xFF0C;&#x5BF9;&#x4F4E;&#x9891;&#x8BCD;&#x654F;&#x611F;&#x3002;&#x9ED8;&#x8BA4;sg=0&#x4E3A;CBOW&#x7B97;&#x6CD5;&#x3002;
size: &#x662F;&#x8F93;&#x51FA;&#x8BCD;&#x5411;&#x91CF;&#x7684;&#x7EF4;&#x6570;&#xFF0C;&#x4E00;&#x822C;&#x503C;&#x53D6;&#x4E3A;100&#x5230;200&#x4E4B;&#x95F4;&#x3002;
window: &#x662F;&#x53E5;&#x5B50;&#x4E2D;&#x5F53;&#x524D;&#x8BCD;&#x4E0E;&#x76EE;&#x6807;&#x8BCD;&#x4E4B;&#x95F4;&#x7684;&#x6700;&#x5927;&#x8DDD;&#x79BB;&#xFF0C;3&#x8868;&#x793A;&#x5728;&#x76EE;&#x6807;&#x8BCD;&#x524D;&#x770B;3-b&#x4E2A;&#x8BCD;&#xFF0C;&#x540E;&#x9762;&#x770B;b&#x4E2A;&#x8BCD;&#xFF08;b&#x5728;0-3&#x4E4B;&#x95F4;&#x968F;&#x673A;&#xFF09;&#x3002;
min_count: &#x5BF9;&#x8BCD;&#x8FDB;&#x884C;&#x8FC7;&#x6EE4;&#xFF0C;&#x9891;&#x7387;&#x5C0F;&#x4E8E;min-count&#x7684;&#x5355;&#x8BCD;&#x5219;&#x4F1A;&#x88AB;&#x5FFD;&#x89C6;&#xFF0C;&#x9ED8;&#x8BA4;&#x503C;&#x4E3A;5&#x3002;
negative: &#x548C;sample&#x53EF;&#x6839;&#x636E;&#x8BAD;&#x7EC3;&#x7ED3;&#x679C;&#x8FDB;&#x884C;&#x5FAE;&#x8C03;&#xFF0C;sample &#x8868;&#x793A;&#x66F4;&#x9AD8;&#x9891;&#x7387;&#x7684;&#x8BCD;&#x88AB;&#x968F;&#x673A;&#x4E0B;&#x91C7;&#x6837;&#x5230;&#x6240;&#x8BBE;&#x7F6E;&#x7684;&#x9608;&#x503C;&#xFF0C;&#x9ED8;&#x8BA4;&#x503C;&#x4E3A; 1e-3&#x3002;
hs: hs=1&#x8868;&#x793A;&#x5C42;&#x7EA7;softmax&#x5C06;&#x4F1A;&#x88AB;&#x4F7F;&#x7528;&#x3002;&#x9ED8;&#x8BA4;hs=0&#x4E14; negative &#x4E0D;&#x4E3A;0&#xFF0C;&#x5219;&#x8D1F;&#x91C7;&#x6837;&#x5C06;&#x4F1A;&#x88AB;&#x9009;&#x62E9;&#x4F7F;&#x7528;&#x3002;
&quot;&quot;&quot;</span>

<span class="token comment"># &#x8BAD;&#x7EC3;&#x540E;&#x7684;&#x6A21;&#x578B;&#x53EF;&#x4EE5;&#x4FDD;&#x5B58;&#x4E0E;&#x52A0;&#x8F7D;</span>
model<span class="token punctuation">.</span>save<span class="token punctuation">(</span><span class="token string">&apos;model&apos;</span><span class="token punctuation">)</span>  <span class="token comment">#&#x4FDD;&#x5B58;&#x6A21;&#x578B;</span>
model <span class="token operator">=</span> Word2Vec<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">&apos;model&apos;</span><span class="token punctuation">)</span>   <span class="token comment">#&#x52A0;&#x8F7D;&#x6A21;&#x578B;</span>
</code></pre>
<h4 id="doc2vec"><a name="doc2vec" class="anchor-navigation-ex-anchor" href="#doc2vec"><i class="fa fa-link" aria-hidden="true"></i></a>Doc2Vec</h4>
<p>&#x5728; Gensim &#x5E93;&#x4E2D;&#xFF0C;Doc2Vec &#x4E0E; Word2Vec &#x90FD;&#x6781;&#x4E3A;&#x76F8;&#x4F3C;&#x3002;&#x4F46;&#x4E24;&#x8005;&#x5728;&#x5BF9;&#x8F93;&#x5165;&#x6570;&#x636E;&#x7684;&#x9884;&#x5904;&#x7406;&#x4E0A;&#x7A0D;&#x6709;&#x4E0D;&#x540C;&#xFF0C;Doc2vec &#x63A5;&#x6536;&#x4E00;&#x4E2A;&#x7531; LabeledSentence &#x5BF9;&#x8C61;&#x7EC4;&#x6210;&#x7684;&#x8FED;&#x4EE3;&#x5668;&#x4F5C;&#x4E3A;&#x5176;&#x6784;&#x9020;&#x51FD;&#x6570;&#x7684;&#x8F93;&#x5165;&#x53C2;&#x6570;&#x3002;LabeledSentence &#x662F; Gensim &#x5185;&#x5EFA;&#x7684;&#x4E00;&#x4E2A;&#x7C7B;&#xFF0C;&#x5B83;&#x63A5;&#x6536;&#x4E24;&#x4E2A; List &#x4F5C;&#x4E3A;&#x5176;&#x521D;&#x59CB;&#x5316;&#x7684;&#x53C2;&#x6570;&#xFF1A;word list &#x548C; label list&#x3002;</p>
<p>Doc2Vec &#x4E5F;&#x5305;&#x62EC;&#x4E24;&#x79CD;&#x5B9E;&#x73B0;&#x65B9;&#x5F0F;&#xFF1A;DBOW&#xFF08;Distributed Bag of Words&#xFF09;&#x548C; DM &#xFF08;Distributed Memory&#xFF09;&#x3002; dm = 0 &#x6216;&#x8005; dm=1 &#x51B3;&#x5B9A;&#x8C03;&#x7528; DBOW &#x8FD8;&#x662F; DM&#x3002;</p>
<pre class="language-"><code class="lang-python"><span class="token keyword">from</span> gensim<span class="token punctuation">.</span>models<span class="token punctuation">.</span>doc2vec <span class="token keyword">import</span> Doc2Vec<span class="token punctuation">,</span>LabeledSentence

model <span class="token operator">=</span> Doc2Vec<span class="token punctuation">(</span>dm<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> size<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span> window<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">,</span> min_count<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> workers<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>build_vocab<span class="token punctuation">(</span>iter_data<span class="token punctuation">)</span> <span class="token comment"># iter_data = yield LabeledSentence([token,] ,label)</span>
model<span class="token punctuation">.</span>train<span class="token punctuation">(</span>iter_data<span class="token punctuation">,</span>total_examples<span class="token operator">=</span>model<span class="token punctuation">.</span>corpus_count<span class="token punctuation">,</span>epochs<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">,</span>start_alpha<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">,</span>end_alpha <span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">)</span>  <span class="token comment"># start_alpha &#x4E3A;&#x5F00;&#x59CB;&#x5B66;&#x4E60;&#x7387;, &#x5927;&#x4E8E;end_alpha</span>

<span class="token comment">#&#x6839;&#x636E;&#x6807;&#x7B7E;&#x627E;&#x6700;&#x76F8;&#x4F3C;&#x7684;</span>
model<span class="token punctuation">.</span>docvecs<span class="token punctuation">.</span>most_similar<span class="token punctuation">(</span>xx<span class="token punctuation">)</span>
</code></pre>
<h2 id="&#x5206;&#x8BCD;"><a name="&#x5206;&#x8BCD;" class="anchor-navigation-ex-anchor" href="#&#x5206;&#x8BCD;"><i class="fa fa-link" aria-hidden="true"></i></a>1.3. &#x5206;&#x8BCD;</h2>
<pre class="language-"><code class="lang-python"><span class="token keyword">from</span> gensim <span class="token keyword">import</span> corpora
<span class="token comment">#&#x6784;&#x5EFA;&#x8BCD;&#x888B;&#x6A21;&#x578B;</span>
dictionary <span class="token operator">=</span> corpora<span class="token punctuation">.</span>Dictionary<span class="token punctuation">(</span>sentences<span class="token punctuation">)</span>
corpus <span class="token operator">=</span> <span class="token punctuation">[</span>dictionary<span class="token punctuation">.</span>doc2bow<span class="token punctuation">(</span>sentence<span class="token punctuation">)</span> <span class="token keyword">for</span> sentence <span class="token keyword">in</span> sentences<span class="token punctuation">]</span>
</code></pre>
<h3 id="&#x7ED3;&#x5DF4;&#x5206;&#x8BCD;"><a name="&#x7ED3;&#x5DF4;&#x5206;&#x8BCD;" class="anchor-navigation-ex-anchor" href="#&#x7ED3;&#x5DF4;&#x5206;&#x8BCD;"><i class="fa fa-link" aria-hidden="true"></i></a>1.3.1. &#x7ED3;&#x5DF4;&#x5206;&#x8BCD;</h3>
<p>&#x5168;&#x6A21;&#x5F0F;&#x5206;&#x8BCD;&#xFF1A;&#x628A;&#x53E5;&#x5B50;&#x4E2D;&#x6240;&#x6709;&#x7684;&#x53EF;&#x80FD;&#x662F;&#x8BCD;&#x8BED;&#x7684;&#x90FD;&#x626B;&#x63CF;&#x51FA;&#x6765;&#xFF0C;&#x901F;&#x5EA6;&#x975E;&#x5E38;&#x5FEB;&#xFF0C;&#x4F46;&#x4E0D;&#x80FD;&#x89E3;&#x51B3;&#x6B67;&#x4E49;&#x3002;</p>
<pre class="language-"><code class="lang-python"><span class="token keyword">import</span> jieba

jieba<span class="token punctuation">.</span>cut<span class="token punctuation">(</span>sentence<span class="token punctuation">,</span> cut_all<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> HMM<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token triple-quoted-string string">&quot;&quot;&quot;
return: generator.
- sentence: The str(unicode) to be segmented.
- cut_all: Model type. True for full pattern(&#x6240;&#x6709;&#x53EF;&#x80FD;&#x7684;&#x5206;&#x8BCD;&#x7ED3;&#x679C;&#x90FD;&#x626B;&#x63CF;&#x51FA;&#x6765;), False for accurate pattern(&#x5C06;&#x53E5;&#x5B50;&#x6700;&#x7CBE;&#x786E;&#x5730;&#x5207;&#x5F00;,&#x552F;&#x4E00;&#x5207;&#x5206;).
- HMM: Whether to use the Hidden Markov Model.
&quot;&quot;&quot;</span>

<span class="token comment"># return: list.</span>
jieba<span class="token punctuation">.</span>lcut<span class="token punctuation">(</span>sentence<span class="token punctuation">,</span> cut_all<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> HMM<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
</code></pre>
<p>jieba&#x6DFB;&#x52A0;&#x65B0;&#x8BCD;&#xFF1A;</p>
<pre class="language-"><code class="lang-python">jieba<span class="token punctuation">.</span>add_word<span class="token punctuation">(</span>new_word<span class="token punctuation">)</span> <span class="token comment"># &#x6DFB;&#x52A0;&#x539F;&#x8BCD;&#x5178;&#x4E2D;&#x6CA1;&#x6709;&#x7684;</span>
jieba<span class="token punctuation">.</span>load_userdict<span class="token punctuation">(</span><span class="token string">&apos;user_dict.txt&apos;</span><span class="token punctuation">)</span> <span class="token comment"># &#x4F7F;&#x7528;&#x6587;&#x4EF6;</span>
</code></pre>
<h3 id="hanlp&#x5206;&#x8BCD;"><a name="hanlp&#x5206;&#x8BCD;" class="anchor-navigation-ex-anchor" href="#hanlp&#x5206;&#x8BCD;"><i class="fa fa-link" aria-hidden="true"></i></a>1.3.2. hanlp&#x5206;&#x8BCD;</h3>
<p>&#x547D;&#x4EE4;&#x884C;&#x4F7F;&#x7528;&#xFF1A;</p>
<pre class="language-"><code>&gt; hanlp segment  # &#x8FDB;&#x5165;&#x4EA4;&#x4E92;&#x5206;&#x8BCD;&#x6A21;&#x5F0F;
&gt; hanlp serve    # &#x542F;&#x52A8;&#x5185;&#x7F6E;HTTP&#x670D;&#x52A1;&#x5668;&#xFF0C;http://localhost:8765
</code></pre><p>&#x5206;&#x8BCD;&#xFF1A;</p>
<pre class="language-"><code class="lang-python"><span class="token keyword">from</span> pyhanlp <span class="token keyword">import</span> HanLP
<span class="token comment"># return&#xFF1A; jpype._jclass.java.util.ArrayList</span>
HanLP<span class="token punctuation">.</span>segment<span class="token punctuation">(</span>sentence<span class="token punctuation">)</span>
</code></pre>
<p>&#x6DFB;&#x52A0;&#x81EA;&#x5B9A;&#x4E49;&#x65B0;&#x8BCD;&#xFF1A;</p>
<pre class="language-"><code class="lang-python"><span class="token keyword">from</span> pyhanlp <span class="token keyword">import</span> CustomDictionary
CustomDictionary<span class="token punctuation">.</span>add<span class="token punctuation">(</span><span class="token string">&quot;&#x9EC4;&#x94A2;&quot;</span><span class="token punctuation">)</span>
CustomDictionary<span class="token punctuation">.</span>insert<span class="token punctuation">(</span><span class="token string">&quot;&#x65B0;&#x4E61;&#x4FE1;&#x606F;&#x6E2F;&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;nz 1024&quot;</span><span class="token punctuation">)</span>
CustomDictionary<span class="token punctuation">.</span>add<span class="token punctuation">(</span><span class="token string">&quot;&#x4EA4;&#x6613;&#x5E73;&#x53F0;&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;nz 1024 n 1&quot;</span><span class="token punctuation">)</span>
</code></pre>
<h2 id="&#x6587;&#x672C;&#x6458;&#x8981;"><a name="&#x6587;&#x672C;&#x6458;&#x8981;" class="anchor-navigation-ex-anchor" href="#&#x6587;&#x672C;&#x6458;&#x8981;"><i class="fa fa-link" aria-hidden="true"></i></a>1.4. &#x6587;&#x672C;&#x6458;&#x8981;</h2>
<pre class="language-"><code class="lang-python"><span class="token comment"># &#x57FA;&#x4E8E; tf-idf &#x63D0;&#x53D6;&#x5173;&#x952E;&#x5B57;</span>
jieba<span class="token punctuation">.</span>analyse<span class="token punctuation">.</span>extract_tags<span class="token punctuation">(</span>
    sentence<span class="token punctuation">,</span>
    topK<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">,</span>
    withWeight<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>
    allowPOS<span class="token operator">=</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    withFlag<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>
<span class="token triple-quoted-string string">&quot;&quot;&quot;
sentence&#xFF1A;&#x5F85;&#x63D0;&#x53D6;&#x7684;&#x6587;&#x672C;&#x8BED;&#x6599;.
topK&#xFF1A;&#x8FD4;&#x56DE; TF-IDF &#x6743;&#x91CD;&#x6700;&#x5927;&#x7684;&#x5173;&#x952E;&#x8BCD;&#x4E2A;&#x6570;.
withWeight&#xFF1A;&#x662F;&#x5426;&#x9700;&#x8981;&#x8FD4;&#x56DE;&#x5173;&#x952E;&#x8BCD;&#x7684;&#x6743;&#x91CD;&#x503C;.
allowPOS&#xFF1A;&#x4EC5;&#x5305;&#x62EC;&#x6307;&#x5B9A;&#x8BCD;&#x6027;&#x7684;&#x8BCD;&#xFF0C;&#x9ED8;&#x8BA4;&#x503C;&#x4E3A;&#x7A7A;&#xFF0C;&#x5373;&#x4E0D;&#x7B5B;&#x9009;&#x3002;
withFlag&#xFF1A;&#x5F53;allowPOS&#x4E0D;&#x4E3A;&#x7A7A;&#x65F6;&#xFF0C;withFlag=True&#x8FD4;&#x56DE;[(jieba.posseg.pair(word, flag), weight), ]
&quot;&quot;&quot;</span>

<span class="token comment"># &#x57FA;&#x4E8E; TextRank &#x7B97;&#x6CD5;&#x63D0;&#x53D6;&#x5173;&#x952E;&#x8BCD;</span>
jieba<span class="token punctuation">.</span>analyse<span class="token punctuation">.</span>textrank<span class="token punctuation">(</span>
    sentence<span class="token punctuation">,</span>
    topK<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">,</span>
    withWeight<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>
    allowPOS<span class="token operator">=</span><span class="token punctuation">(</span><span class="token string">&apos;ns&apos;</span><span class="token punctuation">,</span> <span class="token string">&apos;n&apos;</span><span class="token punctuation">,</span> <span class="token string">&apos;vn&apos;</span><span class="token punctuation">,</span> <span class="token string">&apos;v&apos;</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    withFlag<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>

<span class="token comment"># &#x57FA;&#x4E8E; LDA &#x4E3B;&#x9898;&#x6A21;&#x578B;&#x63D0;&#x53D6;&#x5173;&#x952E;&#x8BCD;</span>

<span class="token comment"># &#x6784;&#x5EFA;&#x8BCD;&#x888B;&#x6A21;&#x578B;&#xFF0C;sentences&#x662F;[[token,],[token,]]</span>
dictionary <span class="token operator">=</span> corpora<span class="token punctuation">.</span>Dictionary<span class="token punctuation">(</span>sentences<span class="token punctuation">)</span>
corpus <span class="token operator">=</span> <span class="token punctuation">[</span>dictionary<span class="token punctuation">.</span>doc2bow<span class="token punctuation">(</span>sentence<span class="token punctuation">)</span> <span class="token keyword">for</span> sentence <span class="token keyword">in</span> sentences<span class="token punctuation">]</span>

<span class="token comment"># LDA&#x6A21;&#x578B;&#xFF0C;num_topics&#x662F;&#x4E3B;&#x9898;&#x7684;&#x4E2A;&#x6570;</span>
lda <span class="token operator">=</span> gensim<span class="token punctuation">.</span>models<span class="token punctuation">.</span>ldamodel<span class="token punctuation">.</span>LdaModel<span class="token punctuation">(</span>corpus<span class="token operator">=</span>corpus<span class="token punctuation">,</span> id2word<span class="token operator">=</span>dictionary<span class="token punctuation">,</span> num_topics<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span>
lda<span class="token punctuation">.</span>print_topic<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> topn<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span>
</code></pre>
<pre class="language-"><code class="lang-python"><span class="token keyword">from</span> pyhanlp <span class="token keyword">import</span> HanLP
<span class="token comment"># &#x5185;&#x90E8;&#x91C7;&#x7528; TextRankKeyword &#x5B9E;&#x73B0;</span>
result <span class="token operator">=</span> HanLP<span class="token punctuation">.</span>extractKeyword<span class="token punctuation">(</span>sentence<span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">)</span>  <span class="token comment"># java.util.ArrayList</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>result<span class="token punctuation">)</span>
</code></pre>
<h2 id="&#x6A21;&#x578B;"><a name="&#x6A21;&#x578B;" class="anchor-navigation-ex-anchor" href="#&#x6A21;&#x578B;"><i class="fa fa-link" aria-hidden="true"></i></a>1.5. &#x6A21;&#x578B;</h2>
<p>HMM&#x6A21;&#x578B;</p>
<p>LDA&#x4E3B;&#x9898;&#x6A21;&#x578B;</p>
<pre class="language-"><code class="lang-python">gensim<span class="token punctuation">.</span>models<span class="token punctuation">.</span>ldamodel<span class="token punctuation">.</span>LdaModel

<span class="token comment">#&#x6784;&#x5EFA;&#x8BCD;&#x888B;&#x6A21;&#x578B;</span>
dictionary <span class="token operator">=</span> corpora<span class="token punctuation">.</span>Dictionary<span class="token punctuation">(</span>sentences<span class="token punctuation">)</span>
corpus <span class="token operator">=</span> <span class="token punctuation">[</span>dictionary<span class="token punctuation">.</span>doc2bow<span class="token punctuation">(</span>sentence<span class="token punctuation">)</span> <span class="token keyword">for</span> sentence <span class="token keyword">in</span> sentences<span class="token punctuation">]</span>

<span class="token comment">#lda&#x6A21;&#x578B;&#xFF0C;num_topics&#x662F;&#x4E3B;&#x9898;&#x7684;&#x4E2A;&#x6570;</span>
lda <span class="token operator">=</span> gensim<span class="token punctuation">.</span>models<span class="token punctuation">.</span>ldamodel<span class="token punctuation">.</span>LdaModel<span class="token punctuation">(</span>corpus<span class="token operator">=</span>corpus<span class="token punctuation">,</span> id2word<span class="token operator">=</span>dictionary<span class="token punctuation">,</span> num_topics<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span>
</code></pre>
<p>&#x8D1D;&#x53F6;&#x65AF;&#x5206;&#x7C7B;&#x6A21;&#x578B;&#xFF1A;</p>
<pre class="language-"><code class="lang-python"><span class="token comment"># &#x5206;&#x522B;&#x8FDB;&#x884C;&#x7B97;&#x6CD5;&#x5EFA;&#x6A21;&#x548C;&#x6A21;&#x578B;&#x8BAD;&#x7EC3;&#x3002;</span>
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>naive_bayes <span class="token keyword">import</span> MultinomialNB

classifier <span class="token operator">=</span> MultinomialNB<span class="token punctuation">(</span><span class="token punctuation">)</span>
classifier<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>vec<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>vec_train<span class="token punctuation">)</span><span class="token punctuation">,</span> label_train<span class="token punctuation">)</span>
classifier<span class="token punctuation">.</span>score<span class="token punctuation">(</span>vec<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>vec_test<span class="token punctuation">)</span><span class="token punctuation">,</span> label_test<span class="token punctuation">)</span>
</code></pre>
<p>SVM&#x5206;&#x7C7B;&#x6A21;&#x578B;&#xFF1A;</p>
<pre class="language-"><code class="lang-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>svm <span class="token keyword">import</span> SVC

svm <span class="token operator">=</span> SVC<span class="token punctuation">(</span>kernel<span class="token operator">=</span><span class="token string">&apos;linear&apos;</span><span class="token punctuation">)</span>
svm<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>vec<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>vec_train<span class="token punctuation">)</span><span class="token punctuation">,</span> label_train<span class="token punctuation">)</span>
svm<span class="token punctuation">.</span>score<span class="token punctuation">(</span>vec<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>vec_test<span class="token punctuation">)</span><span class="token punctuation">,</span> label_test<span class="token punctuation">)</span>
</code></pre>
<p>&#x51B3;&#x7B56;&#x6811;&#x3001;&#x968F;&#x673A;&#x68EE;&#x6797;&#x3001;XGBoost&#x3001;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x7B49;</p>
<h2 id="&#x6587;&#x672C;&#x805A;&#x7C7B;"><a name="&#x6587;&#x672C;&#x805A;&#x7C7B;" class="anchor-navigation-ex-anchor" href="#&#x6587;&#x672C;&#x805A;&#x7C7B;"><i class="fa fa-link" aria-hidden="true"></i></a>1.6. &#x6587;&#x672C;&#x805A;&#x7C7B;</h2>
<p>k-means&#x6A21;&#x578B;&#xFF1A;</p>
<pre class="language-"><code class="lang-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>cluster <span class="token keyword">import</span> KMeans
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>decomposition <span class="token keyword">import</span> PCA

<span class="token comment"># n_clusters&#x9700;&#x8981;&#x624B;&#x52A8;&#x6307;&#x5B9A;&#xFF0C;&#x5206;&#x4E3A;4&#x7C7B;&#xFF0C;&#x8FD9;&#x91CC;&#x4E5F;&#x53EF;&#x4EE5;&#x9009;&#x62E9;&#x968F;&#x673A;&#x521D;&#x59CB;&#x5316;init=&quot;random&quot;</span>
clf <span class="token operator">=</span> KMeans<span class="token punctuation">(</span>n_clusters<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span> max_iter<span class="token operator">=</span><span class="token number">10000</span><span class="token punctuation">,</span> init<span class="token operator">=</span><span class="token string">&quot;k-means++&quot;</span><span class="token punctuation">,</span> tol<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">6</span><span class="token punctuation">)</span>


pca <span class="token operator">=</span> PCA<span class="token punctuation">(</span>n_components<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span>            <span class="token comment"># &#x964D;&#x7EF4;</span>
TnewData <span class="token operator">=</span> pca<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>weight<span class="token punctuation">)</span>  <span class="token comment"># &#x5C06;weight&#x53D8;&#x4E3A;10&#x7EF4;&#x7684;&#x5411;&#x91CF;</span>

s <span class="token operator">=</span> clf<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>TnewData<span class="token punctuation">)</span>   <span class="token comment"># &#x8BAD;&#x7EC3;&#x6A21;&#x578B;</span>

clf<span class="token punctuation">.</span>cluster_centers_  <span class="token comment"># &#x805A;&#x7C7B;&#x540E;&#x7684;[&#x4E2D;&#x5FC3;&#x5411;&#x91CF;,]</span>
</code></pre>
<p>&#x91C7;&#x7528;&#x57FA;&#x4E8E;&#x5BC6;&#x5EA6;&#x7684; DBSCAN&#x3001;&#x5C42;&#x6B21;&#x805A;&#x7C7B;&#x7B49;&#x7B97;&#x6CD5;</p>
<h2 id="&#x964D;&#x7EF4;&#x5DE5;&#x5177;"><a name="&#x964D;&#x7EF4;&#x5DE5;&#x5177;" class="anchor-navigation-ex-anchor" href="#&#x964D;&#x7EF4;&#x5DE5;&#x5177;"><i class="fa fa-link" aria-hidden="true"></i></a>1.7. &#x964D;&#x7EF4;&#x5DE5;&#x5177;</h2>
<p> PCA&#xFF1A;</p>
<pre class="language-"><code class="lang-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>decomposition <span class="token keyword">import</span> PCA

pca <span class="token operator">=</span> PCA<span class="token punctuation">(</span>n_components<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span>             <span class="token comment"># &#x964D;&#x7EF4;</span>
TnewData <span class="token operator">=</span> pca<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>weight<span class="token punctuation">)</span>  <span class="token comment"># &#x5C06;weight&#x53D8;&#x4E3A;10&#x7EF4;&#x7684;&#x5411;&#x91CF;</span>
</code></pre>
<p>TSNE:</p>
<pre class="language-"><code class="lang-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>manifold <span class="token keyword">import</span> TSNE

ts <span class="token operator">=</span>TSNE<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span>
newData <span class="token operator">=</span> ts<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>weight<span class="token punctuation">)</span>
</code></pre>
<p>&#x4E24;&#x8005;&#x540C;&#x4E3A;&#x964D;&#x7EF4;&#x5DE5;&#x5177;&#xFF0C;&#x4E3B;&#x8981;&#x533A;&#x522B;&#x5728;&#x4E8E;&#xFF0C;&#x6240;&#x5728;&#x7684;&#x5305;&#x4E0D;&#x540C;&#xFF08;&#x4E5F;&#x5373;&#x673A;&#x5236;&#x548C;&#x539F;&#x7406;&#x4E0D;&#x540C;&#xFF09;&#x3002;</p>
<p>&#x56E0;&#x4E3A;&#x539F;&#x7406;&#x4E0D;&#x540C;&#xFF0C;&#x5BFC;&#x81F4; TSNE &#x4FDD;&#x7559;&#x4E0B;&#x7684;&#x5C5E;&#x6027;&#x4FE1;&#x606F;&#xFF0C;&#x66F4;&#x5177;&#x4EE3;&#x8868;&#x6027;&#xFF0C;&#x4E5F;&#x5373;&#x6700;&#x80FD;&#x4F53;&#x73B0;&#x6837;&#x672C;&#x95F4;&#x7684;&#x5DEE;&#x5F02;&#xFF0C;&#x4F46;&#x662F; TSNE &#x8FD0;&#x884C;&#x6781;&#x6162;&#xFF0C;PCA &#x5219;&#x76F8;&#x5BF9;&#x8F83;&#x5FEB;&#x3002;</p>
<h2 id="&#x6587;&#x672C;&#x5206;&#x7C7B;"><a name="&#x6587;&#x672C;&#x5206;&#x7C7B;" class="anchor-navigation-ex-anchor" href="#&#x6587;&#x672C;&#x5206;&#x7C7B;"><i class="fa fa-link" aria-hidden="true"></i></a>1.8. &#x6587;&#x672C;&#x5206;&#x7C7B;</h2>
<p>&#x5E8F;&#x5217;&#x6570;&#x636E;&#x7684;&#x5904;&#x7406;&#xFF0C;&#x6211;&#x4EEC;&#x4ECE;&#x8BED;&#x8A00;&#x6A21;&#x578B; N-gram &#x6A21;&#x578B;&#x8BF4;&#x8D77;&#xFF0C;&#x7136;&#x540E;&#x7740;&#x91CD;&#x8C08;&#x8C08; RNN&#xFF0C;&#x5E76;&#x901A;&#x8FC7; RNN &#x7684;&#x53D8;&#x79CD; LSTM &#x548C; GRU &#x6765;&#x5B9E;&#x6218;&#x6587;&#x672C;&#x5206;&#x7C7B;&#x3002;</p>
<p>RNN&#xFF1A;&#x5FAA;&#x73AF;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#xFF08;Recurrent Neural Network&#xFF09;</p>
<ul>
<li>LSTM</li>
<li>GRU&#xFF08;Gated Recurrent Unit&#xFF09;&#xFF0C;&#x7B80;&#x5316;&#x7248;&#x7684; LSTM&#x3002;</li>
</ul>
<h2 id="&#x60C5;&#x611F;&#x5206;&#x6790;"><a name="&#x60C5;&#x611F;&#x5206;&#x6790;" class="anchor-navigation-ex-anchor" href="#&#x60C5;&#x611F;&#x5206;&#x6790;"><i class="fa fa-link" aria-hidden="true"></i></a>1.9. &#x60C5;&#x611F;&#x5206;&#x6790;</h2>
<ol>
<li>&#x4E2D;&#x6587;&#x60C5;&#x611F;&#x5206;&#x6790;&#x65B9;&#x6CD5;&#x7B80;&#x4ECB;&#xFF1B;</li>
<li>SnowNLP &#x5FEB;&#x901F;&#x8FDB;&#x884C;&#x8BC4;&#x8BBA;&#x6570;&#x636E;&#x60C5;&#x611F;&#x5206;&#x6790;&#xFF1B;</li>
<li>&#x57FA;&#x4E8E;&#x6807;&#x6CE8;&#x597D;&#x7684;&#x60C5;&#x611F;&#x8BCD;&#x5178;&#x6765;&#x8BA1;&#x7B97;&#x60C5;&#x611F;&#x503C;&#xFF1B;</li>
<li>pytreebank &#x7ED8;&#x5236;&#x60C5;&#x611F;&#x6811;&#xFF1B;</li>
</ol>
<p>&#x60C5;&#x611F;&#x503E;&#x5411;&#x53EF;&#x8BA4;&#x4E3A;&#x662F;&#x4E3B;&#x4F53;&#x5BF9;&#x67D0;&#x4E00;&#x5BA2;&#x4F53;&#x4E3B;&#x89C2;&#x5B58;&#x5728;&#x7684;&#x5185;&#x5FC3;&#x559C;&#x6076;&#xFF0C;&#x5185;&#x5728;&#x8BC4;&#x4EF7;&#x7684;&#x4E00;&#x79CD;&#x503E;&#x5411;&#x3002;&#x5B83;&#x7531;&#x4E24;&#x4E2A;&#x65B9;&#x9762;&#x6765;&#x8861;&#x91CF;&#xFF1A;&#x4E00;&#x4E2A;&#x60C5;&#x611F;&#x503E;&#x5411;&#x65B9;&#x5411;&#xFF0C;&#x4E00;&#x4E2A;&#x662F;&#x60C5;&#x611F;&#x503E;&#x5411;&#x5EA6;&#x3002;</p>
<p>&#x60C5;&#x611F;&#x503E;&#x5411;&#x5206;&#x6790;&#xFF1A;</p>
<ul>
<li>&#x57FA;&#x4E8E;&#x60C5;&#x611F;&#x8BCD;&#x5178;&#x7684;&#x65B9;&#x6CD5;&#xFF1A;&#x9700;&#x8981;&#x7528;&#x5230;&#x6807;&#x6CE8;&#x597D;&#x7684;&#x60C5;&#x611F;&#x8BCD;&#x5178;&#x3002;</li>
<li>&#x57FA;&#x4E8E;&#x673A;&#x5668;&#x5B66;&#x4E60;&#x7684;&#x65B9;&#x6CD5;&#xFF0C;&#x5982;&#x57FA;&#x4E8E;&#x5927;&#x89C4;&#x6A21;&#x8BED;&#x6599;&#x5E93;&#x7684;&#x673A;&#x5668;&#x5B66;&#x4E60;&#x3002;&#x9700;&#x8981;&#x5927;&#x91CF;&#x7684;&#x4EBA;&#x5DE5;&#x6807;&#x6CE8;&#x7684;&#x8BED;&#x6599;&#x4F5C;&#x4E3A;&#x8BAD;&#x7EC3;&#x96C6;&#xFF0C;&#x901A;&#x8FC7;&#x63D0;&#x53D6;&#x6587;&#x672C;&#x7279;&#x5F81;&#xFF0C;&#x6784;&#x5EFA;&#x5206;&#x7C7B;&#x5668;&#x6765;&#x5B9E;&#x73B0;&#x60C5;&#x611F;&#x7684;&#x5206;&#x7C7B;&#x3002;</li>
</ul>
<p>&#x6587;&#x672C;&#x60C5;&#x611F;&#x5206;&#x6790;&#x7684;&#x5206;&#x6790;&#x7C92;&#x5EA6;&#x53EF;&#x4EE5;&#x662F;&#x8BCD;&#x8BED;&#x3001;&#x53E5;&#x5B50;&#x3001;&#x6BB5;&#x843D;&#x6216;&#x7BC7;&#x7AE0;&#x3002;</p>
<p>&#x8BE5;&#x628A;&#x53E5;&#x5B50;&#x4E2D;&#x8BCD;&#x8BED;&#x7684;&#x4F9D;&#x5B58;&#x5173;&#x7CFB;&#x7EB3;&#x5165;&#x5230;&#x53E5;&#x5B50;&#x60C5;&#x611F;&#x7684;&#x8BA1;&#x7B97;&#x8FC7;&#x7A0B;&#x4E2D;&#x53BB;&#xFF0C;&#x4E0D;&#x540C;&#x7684;&#x4F9D;&#x5B58;&#x5173;&#x7CFB;&#xFF0C;&#x8FDB;&#x884C;&#x60C5;&#x611F;&#x503E;&#x5411;&#x8BA1;&#x7B97;&#x662F;&#x4E0D;&#x4E00;&#x6837;&#x7684;&#x3002;</p>
<p>SnowNLP&#x5E93; &#x4E3B;&#x8981;&#x53EF;&#x4EE5;&#x8FDB;&#x884C;&#x4E2D;&#x6587;&#x5206;&#x8BCD;&#x3001;&#x8BCD;&#x6027;&#x6807;&#x6CE8;&#x3001;&#x60C5;&#x611F;&#x5206;&#x6790;&#x3001;&#x6587;&#x672C;&#x5206;&#x7C7B;&#x3001;&#x8F6C;&#x6362;&#x62FC;&#x97F3;&#x3001;&#x7E41;&#x4F53;&#x8F6C;&#x7B80;&#x4F53;&#x3001;&#x63D0;&#x53D6;&#x6587;&#x672C;&#x5173;&#x952E;&#x8BCD;&#x3001;&#x63D0;&#x53D6;&#x6458;&#x8981;&#x3001;&#x5206;&#x5272;&#x53E5;&#x5B50;&#x3001;&#x6587;&#x672C;&#x76F8;&#x4F3C;&#x7B49;&#x3002;</p>
<p>&#x7528; SnowNLP &#x8FDB;&#x884C;&#x60C5;&#x611F;&#x5206;&#x6790;&#xFF0C;&#x5B98;&#x7F51;&#x6307;&#x51FA;&#x8FDB;&#x884C;&#x7535;&#x5546;&#x8BC4;&#x8BBA;&#x7684;&#x51C6;&#x786E;&#x7387;&#x8F83;&#x9AD8;&#xFF0C;&#x5176;&#x5B9E;&#x662F;&#x56E0;&#x4E3A;&#x5B83;&#x7684;&#x8BED;&#x6599;&#x5E93;&#x4E3B;&#x8981;&#x662F;&#x7535;&#x5546;&#x8BC4;&#x8BBA;&#x6570;&#x636E;&#xFF0C;&#x4F46;&#x662F;&#x53EF;&#x4EE5;&#x81EA;&#x5DF1;&#x6784;&#x5EFA;&#x76F8;&#x5173;&#x9886;&#x57DF;&#x8BED;&#x6599;&#x5E93;&#xFF0C;&#x66FF;&#x6362;&#x5355;&#x4E00;&#x7684;&#x7535;&#x5546;&#x8BC4;&#x8BBA;&#x8BED;&#x6599;&#xFF0C;&#x51C6;&#x786E;&#x7387;&#x4E5F;&#x633A;&#x4E0D;&#x9519;&#x7684;&#x3002;</p>
<p>&#x884C;&#x4E1A;&#x6807;&#x51C6;&#x7684;&#x60C5;&#x611F;&#x8BCD;&#x5178;&#x2014;&#x2014;&#x73BB;&#x68EE;&#x60C5;&#x611F;&#x8BCD;&#x5178;</p>
<footer class="page-footer"><span class="copyright">Copyright @appwhy all right reserved&#xFF0C;powered by Gitbook</span><span class="footer-modification">&#x6587;&#x4EF6;&#x66F4;&#x65B0;&#x4E8E;&#xFF1A;
2020-06-17 09:37:25
</span></footer>
                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                <a href="NLP.html" class="navigation navigation-prev " aria-label="Previous page: nlp">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
                <a href="../python/python.html" class="navigation navigation-next " aria-label="Next page: python">
                    <i class="fa fa-angle-right"></i>
                </a>
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"NLP 相关算法","level":"2.1.1","depth":2,"next":{"title":"python","level":"3.1","depth":1,"path":"python/python.md","ref":"python/python.md","articles":[{"title":"python其他库","level":"3.1.1","depth":2,"path":"python/python其他库.md","ref":"python/python其他库.md","articles":[]},{"title":"python常用库","level":"3.1.2","depth":2,"path":"python/python常用库.md","ref":"python/python常用库.md","articles":[]},{"title":"python环境","level":"3.1.3","depth":2,"path":"python/python环境.md","ref":"python/python环境.md","articles":[]},{"title":"基础知识","level":"3.1.4","depth":2,"path":"python/基础知识.md","ref":"python/基础知识.md","articles":[]},{"title":"小技巧","level":"3.1.5","depth":2,"path":"python/小技巧.md","ref":"python/小技巧.md","articles":[]},{"title":"常用知识点","level":"3.1.6","depth":2,"path":"python/常用知识点.md","ref":"python/常用知识点.md","articles":[]},{"title":"常见问题","level":"3.1.7","depth":2,"path":"python/常见问题.md","ref":"python/常见问题.md","articles":[]}]},"previous":{"title":"nlp","level":"2.1","depth":1,"path":"nlp/NLP.md","ref":"nlp/NLP.md","articles":[{"title":"NLP 相关算法","level":"2.1.1","depth":2,"path":"nlp/NLP 相关算法.md","ref":"nlp/NLP 相关算法.md","articles":[]}]},"dir":"ltr"},"config":{"plugins":["-lunr","-search","search-pro","-sharing","-highlight","prism","prism-themes","code","github","mermaid-gb3","splitter","anchor-navigation-ex","3-ba","splitter","simple-page-toc","tbfed-pagefooter"],"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"pluginsConfig":{"tbfed-pagefooter":{"copyright":"Copyright @appwhy","modify_label":"文件更新于：","modify_format":"YYYY-MM-DD HH:mm:ss"},"prism":{"css":["prism-themes/themes/prism-base16-ateliersulphurpool.light.css"]},"github":{"url":"https://github.com/appwhy"},"simple-page-toc":{},"splitter":{},"search-pro":{},"code":{"copyButtons":true},"fontsettings":{"theme":"white","family":"sans","size":2},"mermaid-gb3":{},"anchor-navigation-ex":{"associatedWithSummary":true,"float":{"floatIcon":"fa fa-navicon","level1Icon":"","level2Icon":"","level3Icon":"","showLevelIcon":false},"mode":"float","multipleH1":true,"pageTop":{"level1Icon":"","level2Icon":"","level3Icon":"","showLevelIcon":false},"printLog":false,"showGoTop":true,"showLevel":true},"prism-themes":{},"3-ba":{"configuration":"auto","token":"20b05c51dc78c5786b84d16d003150ac"},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false}},"theme":"default","author":"appwhy","pdf":{"pageNumbers":true,"fontSize":12,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56}},"structure":{"langs":"LANGS.md","readme":"introduction.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"variables":{},"title":"python_book","language":"zh-hans","links":{"sidebar":{"Home":"https://github.com/appwhy"}},"gitbook":"*","description":"记录python知识点"},"file":{"path":"nlp/NLP 相关算法.md","mtime":"2020-06-17T01:37:25.962Z","type":"markdown"},"gitbook":{"version":"3.2.3","time":"2020-06-28T13:42:34.719Z"},"basePath":"..","book":{"language":""}});
        });
    </script>
</div>

        
    
    <script src="../gitbook/gitbook.js"></script>
    <script src="../gitbook/theme.js"></script>
    
        
        <script src="../gitbook/gitbook-plugin-search-pro/jquery.mark.min.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search-pro/search.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-code/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-github/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-mermaid-gb3/book/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-splitter/splitter.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-3-ba/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-fontsettings/fontsettings.js"></script>
        
    

    <script src="../gitbook/gitbook-plugin-mermaid-gb3/mermaid/mermaid.min.js"></script>

    </body>
</html>

